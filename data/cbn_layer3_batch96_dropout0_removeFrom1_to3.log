Will save checkpoints to data/cbn_layer3_batch96_dropout0_removeFrom1_to3.pt
Reading features from data/train_features.h5
Reading questions from  data/train_questions.h5
Reading question data into memory
Reading features from data/val_features.h5
Reading questions from  data/val_questions.h5
Reading question data into memory
device count = 2
Here is the conditioning network:
DataParallel (
  (module): FiLMGen (
    (encoder_embed): Embedding(93, 200)
    (encoder_rnn): GRU(200, 4096, batch_first=True)
    (decoder_linear): Linear (4096 -> 1536)
  )
)
Here is the conditioned network:
FiLMedNet (
  (stem): Sequential (
    (0): Conv2d(1026, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (0): FiLMedResBlock (
    (input_proj): Conv2d(130, 128, kernel_size=(1, 1), stride=(1, 1))
    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (cbn): CBN (
    )
    (film): FiLM (
    )
  )
  (1): FiLMedResBlock (
    (input_proj): Conv2d(130, 128, kernel_size=(1, 1), stride=(1, 1))
    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (cbn): CBN (
    )
    (film): FiLM (
    )
  )
  (2): FiLMedResBlock (
    (input_proj): Conv2d(130, 128, kernel_size=(1, 1), stride=(1, 1))
    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (cbn): CBN (
    )
    (film): FiLM (
    )
  )
  (classifier): Sequential (
    (0): Conv2d(130, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
    (3): MaxPool2d (size=(14, 14), stride=(14, 14), dilation=(1, 1))
    (4): Flatten (
    )
    (5): Linear (512 -> 1024)
    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)
    (7): ReLU (inplace)
    (8): Linear (1024 -> 32)
  )
)
train_loader has 350000 samples
val_loader has 75000 samples
Starting epoch 1
Starting epoch 2
Starting epoch 3
10000 2.6194630888223647
Starting epoch 4
Starting epoch 5
Starting epoch 6
20000 2.563458036184311
Starting epoch 7
Starting epoch 8
Starting epoch 9
30000 2.54042425596714
Starting epoch 10
Starting epoch 11
40000 2.5212416863441467
Starting epoch 12
Starting epoch 13
Starting epoch 14
50000 2.494389785504341
Starting epoch 15
Starting epoch 16
Starting epoch 17
60000 2.4614501757621765
Starting epoch 18
Starting epoch 19
Checking training accuracy ... 
train accuracy is 0.2453244884910486
Checking validation accuracy ...
val accuracy is  0.20833333333333334
Saving checkpoint to data/cbn_layer3_batch96_dropout0_removeFrom1_to3.pt
Starting epoch 20
70000 2.42377240653038
Starting epoch 21
Starting epoch 22
80000 2.383806820845604
Starting epoch 23
Starting epoch 24
Starting epoch 25
90000 2.34029877974987
Starting epoch 26
Starting epoch 27
Starting epoch 28
100000 2.305170529580116
Starting epoch 29
Starting epoch 30
Starting epoch 31
110000 2.2762779634833334
Starting epoch 32
Starting epoch 33
120000 2.2500613184571265
Starting epoch 34
Starting epoch 35
Starting epoch 36
130000 2.222109303510189
Starting epoch 37
Checking training accuracy ... 
train accuracy is 0.27070012787723785
Checking validation accuracy ...
val accuracy is  0.19776
Saving checkpoint to data/cbn_layer3_batch96_dropout0_removeFrom1_to3.pt
